"""
ì—°í•©í•™ìŠµ í´ë¼ì´ì–¸íŠ¸
ë¡œì»¬ ë°ì´í„°ë¡œ í•™ìŠµí•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ì„œë²„ë¡œ ì „ì†¡
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
from torch.utils.data import DataLoader
from typing import Dict, Optional
import requests
import time
import copy
from tqdm import tqdm

from models.cnn import DefectClassifierCNN
from models.few_shot_cnn import HybridCNN


class FederatedClient:
    """
    ì—°í•©í•™ìŠµ í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
    ë¡œì»¬ ë°ì´í„°ë¡œ CNN ëª¨ë¸ì„ í•™ìŠµí•˜ê³  ê°€ì¤‘ì¹˜ë¥¼ ì„œë²„ì™€ êµí™˜
    """
    
    def __init__(
        self,
        client_id: int,
        server_url: str = 'http://localhost:5000',
        model: Optional[DefectClassifierCNN] = None,
        device: Optional[torch.device] = None
    ):
        """
        Args:
            client_id: í´ë¼ì´ì–¸íŠ¸ ID
            server_url: ì„œë²„ URL
            model: CNN ëª¨ë¸ (Noneì´ë©´ ì„œë²„ì—ì„œ ê°€ì ¸ì˜´)
            device: í•™ìŠµ ë””ë°”ì´ìŠ¤
        """
        self.client_id = client_id
        self.server_url = server_url
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        if model is None:
            # ì„œë²„ì—ì„œ ì´ˆê¸° ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
            self.model = None
            self._fetch_initial_weights()
        else:
            self.model = model.to(self.device)
        
        # í•™ìŠµ ì„¤ì •
        self.criterion = nn.CrossEntropyLoss()
        self.optimizer = None
    
    def _fetch_initial_weights(self):
        """ì„œë²„ì—ì„œ ì´ˆê¸° ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = requests.get(f'{self.server_url}/get_weights', timeout=10)
            if response.status_code == 200:
                data = response.json()
                weights = self._deserialize_weights(data['weights'])
                
                # ëª¨ë¸ êµ¬ì¡°ëŠ” ì„œë²„ì—ì„œ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ, ì„ì‹œë¡œ ì‘ì€ ëª¨ë¸ ìƒì„±
                # ì‹¤ì œë¡œëŠ” ì„œë²„ì—ì„œ ëª¨ë¸ êµ¬ì¡° ì •ë³´ë„ í•¨ê»˜ ì „ì†¡í•´ì•¼ í•¨
                num_classes = self._infer_num_classes(weights)
                self.model = DefectClassifierCNN(num_classes=num_classes).to(self.device)
                self.model.load_state_dict(weights)
                print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] ì„œë²„ì—ì„œ ì´ˆê¸° ê°€ì¤‘ì¹˜ ìˆ˜ì‹  ì™„ë£Œ")
            else:
                print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] ì„œë²„ì— ê°€ì¤‘ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤. ëœë¤ ì´ˆê¸°í™”")
                # ê¸°ë³¸ ëª¨ë¸ ìƒì„± (ì‹¤ì œë¡œëŠ” ì„œë²„ì™€ ë™ì¼í•œ êµ¬ì¡°ì—¬ì•¼ í•¨)
                self.model = DefectClassifierCNN(num_classes=10).to(self.device)
        except Exception as e:
            print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            # ê¸°ë³¸ ëª¨ë¸ ìƒì„±
            self.model = DefectClassifierCNN(num_classes=10).to(self.device)
    
    def _infer_num_classes(self, weights: Dict) -> int:
        """ê°€ì¤‘ì¹˜ì—ì„œ í´ë˜ìŠ¤ ìˆ˜ ì¶”ë¡ """
        # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ ì¶œë ¥ í¬ê¸°ì—ì„œ í´ë˜ìŠ¤ ìˆ˜ ì¶”ë¡ 
        for key in reversed(list(weights.keys())):
            if 'classifier' in key and 'weight' in key:
                return weights[key].shape[0]
        return 10  # ê¸°ë³¸ê°’
    
    def train_local(
        self,
        train_loader: DataLoader,
        epochs: int = 1,
        learning_rate: float = 0.001,
        use_few_shot: bool = False,
        few_shot_loader: Optional[DataLoader] = None
    ) -> Dict:
        """
        ë¡œì»¬ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ
        
        Args:
            train_loader: í•™ìŠµ ë°ì´í„° ë¡œë” (ì¼ë°˜ í•™ìŠµìš©)
            epochs: ì—í­ ìˆ˜
            learning_rate: í•™ìŠµë¥ 
            use_few_shot: í“¨ìƒ· í•™ìŠµ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
            few_shot_loader: í“¨ìƒ· í•™ìŠµìš© ë°ì´í„° ë¡œë”
            
        Returns:
            í•™ìŠµ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # í“¨ìƒ· í•™ìŠµ ëª¨ë“œ
        if use_few_shot and few_shot_loader is not None:
            return self._train_few_shot(few_shot_loader, epochs)
        
        # ì¼ë°˜ í•™ìŠµ ëª¨ë“œ
        print(f"\n{'='*70}")
        print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] ì¼ë°˜ í•™ìŠµ ëª¨ë“œ ì‹œì‘")
        print(f"{'='*70}")
        print(f"  - ì´ ì—í­: {epochs}")
        print(f"  - í•™ìŠµë¥ : {learning_rate}")
        print(f"  - ë°°ì¹˜ ìˆ˜: {len(train_loader)}")
        print(f"  - ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"{'='*70}\n")
        
        self.model.train()
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)
        
        total_loss = 0.0
        total_samples = 0
        correct = 0
        
        for epoch in range(epochs):
            epoch_loss = 0.0
            epoch_samples = 0
            epoch_correct = 0
            
            # ì§„í–‰ ë°” ìƒì„±
            pbar = tqdm(
                train_loader,
                desc=f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] Epoch {epoch+1}/{epochs}",
                unit="batch",
                ncols=100
            )
            
            for batch_idx, batch in enumerate(pbar):
                images = batch['image'].to(self.device)
                labels = batch['label'].to(self.device)
                
                # Forward pass
                self.optimizer.zero_grad()
                outputs = self.model(images)
                loss = self.criterion(outputs, labels)
                
                # Backward pass
                loss.backward()
                self.optimizer.step()
                
                # í†µê³„
                batch_size = images.size(0)
                epoch_loss += loss.item() * batch_size
                epoch_samples += batch_size
                
                # ì •í™•ë„ ê³„ì‚°
                _, predicted = torch.max(outputs.data, 1)
                batch_correct = (predicted == labels).sum().item()
                epoch_correct += batch_correct
                correct += batch_correct
                
                # ì§„í–‰ ë°” ì—…ë°ì´íŠ¸
                current_loss = epoch_loss / epoch_samples if epoch_samples > 0 else 0.0
                current_acc = epoch_correct / epoch_samples if epoch_samples > 0 else 0.0
                pbar.set_postfix({
                    'Loss': f'{current_loss:.4f}',
                    'Acc': f'{current_acc:.4f}',
                    'Batch': f'{batch_idx+1}/{len(train_loader)}'
                })
            
            pbar.close()
            
            total_loss += epoch_loss
            total_samples += epoch_samples
            
            avg_loss = epoch_loss / epoch_samples if epoch_samples > 0 else 0.0
            accuracy = correct / total_samples if total_samples > 0 else 0.0
            
            print(f"\n[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] Epoch {epoch+1}/{epochs} ì™„ë£Œ")
            print(f"  â”œâ”€ í‰ê·  ì†ì‹¤: {avg_loss:.6f}")
            print(f"  â”œâ”€ ì •í™•ë„: {accuracy:.4f} ({correct}/{total_samples})")
            print(f"  â””â”€ ì²˜ë¦¬ ìƒ˜í”Œ ìˆ˜: {epoch_samples}ê°œ\n")
        
        final_stats = {
            'loss': total_loss / total_samples if total_samples > 0 else 0.0,
            'accuracy': accuracy,
            'samples': total_samples
        }
        
        print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] í•™ìŠµ ì™„ë£Œ!")
        print(f"  â”œâ”€ ìµœì¢… ì†ì‹¤: {final_stats['loss']:.6f}")
        print(f"  â”œâ”€ ìµœì¢… ì •í™•ë„: {final_stats['accuracy']:.4f}")
        print(f"  â””â”€ ì´ ìƒ˜í”Œ ìˆ˜: {final_stats['samples']}ê°œ\n")
        
        return final_stats
    
    def _train_few_shot(
        self,
        few_shot_loader: DataLoader,
        epochs: int = 1
    ) -> Dict:
        """
        í“¨ìƒ· í•™ìŠµ ìˆ˜í–‰
        
        Args:
            few_shot_loader: í“¨ìƒ· í•™ìŠµìš© ë°ì´í„° ë¡œë”
            epochs: ì—í”¼ì†Œë“œ ìˆ˜
            
        Returns:
            í•™ìŠµ í†µê³„ ë”•ì…”ë„ˆë¦¬
        """
        # HybridCNN ëª¨ë¸ì¸ì§€ í™•ì¸
        if not hasattr(self.model, 'few_shot_episode'):
            raise ValueError("ëª¨ë¸ì´ í“¨ìƒ· í•™ìŠµì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. HybridCNNì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        
        print(f"\n{'='*70}")
        print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] í“¨ìƒ· í•™ìŠµ ëª¨ë“œ ì‹œì‘")
        print(f"{'='*70}")
        print(f"  - ì´ ì—í­: {epochs}")
        print(f"  - ì—í”¼ì†Œë“œ ìˆ˜: {len(few_shot_loader)}")
        print(f"  - ë””ë°”ì´ìŠ¤: {self.device}")
        print(f"{'='*70}\n")
        
        total_accuracy = 0.0
        total_episodes = 0
        total_correct = 0
        total_query_samples = 0
        
        for epoch in range(epochs):
            epoch_accuracy = 0.0
            epoch_episodes = 0
            epoch_correct = 0
            epoch_query_samples = 0
            
            # ì§„í–‰ ë°” ìƒì„±
            pbar = tqdm(
                few_shot_loader,
                desc=f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] Few-shot Epoch {epoch+1}/{epochs}",
                unit="episode",
                ncols=100
            )
            
            for episode_idx, batch in enumerate(pbar):
                support_images = batch['support_images'][0].to(self.device)
                support_labels = batch['support_labels'][0].to(self.device)
                query_images = batch['query_images'][0].to(self.device)
                query_labels = batch['query_labels'][0].to(self.device)
                
                # í“¨ìƒ· í•™ìŠµ ì—í”¼ì†Œë“œ ìˆ˜í–‰
                result = self.model.few_shot_episode(
                    support_images=support_images,
                    support_labels=support_labels,
                    query_images=query_images,
                    query_labels=query_labels
                )
                
                accuracy = result['accuracy'].item()
                episode_correct = result.get('correct', 0)
                episode_total = result.get('total', len(query_labels))
                
                epoch_accuracy += accuracy
                epoch_episodes += 1
                epoch_correct += episode_correct
                epoch_query_samples += episode_total
                
                # ì§„í–‰ ë°” ì—…ë°ì´íŠ¸
                current_acc = epoch_accuracy / epoch_episodes if epoch_episodes > 0 else 0.0
                pbar.set_postfix({
                    'Acc': f'{current_acc:.4f}',
                    'Ep': f'{episode_idx+1}/{len(few_shot_loader)}'
                })
            
            pbar.close()
            
            avg_accuracy = epoch_accuracy / epoch_episodes if epoch_episodes > 0 else 0.0
            total_accuracy += epoch_accuracy
            total_episodes += epoch_episodes
            total_correct += epoch_correct
            total_query_samples += epoch_query_samples
            
            print(f"\n[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] Few-shot Epoch {epoch+1}/{epochs} ì™„ë£Œ")
            print(f"  â”œâ”€ í‰ê·  ì •í™•ë„: {avg_accuracy:.4f}")
            print(f"  â”œâ”€ ì •í™•íˆ ë¶„ë¥˜: {epoch_correct}/{epoch_query_samples}")
            print(f"  â””â”€ ì²˜ë¦¬ ì—í”¼ì†Œë“œ ìˆ˜: {epoch_episodes}ê°œ\n")
        
        final_accuracy = total_accuracy / total_episodes if total_episodes > 0 else 0.0
        
        final_stats = {
            'loss': 0.0,  # í“¨ìƒ· í•™ìŠµì€ loss ëŒ€ì‹  accuracy ì‚¬ìš©
            'accuracy': final_accuracy,
            'samples': total_episodes
        }
        
        print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] í“¨ìƒ· í•™ìŠµ ì™„ë£Œ!")
        print(f"  â”œâ”€ ìµœì¢… ì •í™•ë„: {final_stats['accuracy']:.4f}")
        print(f"  â”œâ”€ ì´ ì •í™•íˆ ë¶„ë¥˜: {total_correct}/{total_query_samples}")
        print(f"  â””â”€ ì´ ì—í”¼ì†Œë“œ ìˆ˜: {total_episodes}ê°œ\n")
        
        return final_stats
    
    def upload_weights(self, round_num: int, data_size: int) -> bool:
        """
        í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ì„œë²„ë¡œ ì—…ë¡œë“œ
        
        Args:
            round_num: í˜„ì¬ ë¼ìš´ë“œ ë²ˆí˜¸
            data_size: ì‚¬ìš©í•œ ë°ì´í„° í¬ê¸°
            
        Returns:
            ì—…ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] ê°€ì¤‘ì¹˜ ì—…ë¡œë“œ ì¤€ë¹„ ì¤‘...")
        
        # ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
        weights = self.model.get_state_dict()
        
        # ê°€ì¤‘ì¹˜ í¬ê¸° ê³„ì‚°
        total_params = sum(p.numel() for p in weights.values())
        total_size_mb = sum(p.numel() * 4 / (1024 * 1024) for p in weights.values())  # float32 ê¸°ì¤€
        
        print(f"  â”œâ”€ ì´ íŒŒë¼ë¯¸í„° ìˆ˜: {total_params:,}ê°œ")
        print(f"  â”œâ”€ ì˜ˆìƒ í¬ê¸°: {total_size_mb:.2f} MB")
        print(f"  â””â”€ ë°ì´í„° í¬ê¸°: {data_size}ê°œ ìƒ˜í”Œ")
        
        # ì§ë ¬í™”
        weights_serialized = self._serialize_weights(weights)
        
        # ì„œë²„ë¡œ ì „ì†¡
        try:
            payload = {
                'client_id': self.client_id,
                'weights': weights_serialized,
                'data_size': data_size,
                'round': round_num
            }
            
            print(f"  â””â”€ ì„œë²„ë¡œ ì „ì†¡ ì¤‘... ({self.server_url})")
            response = requests.post(
                f'{self.server_url}/upload_weights',
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                response_data = response.json()
                received_clients = response_data.get('received_clients', 0)
                min_clients = response_data.get('min_clients', 0)
                print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âœ… ê°€ì¤‘ì¹˜ ì—…ë¡œë“œ ì„±ê³µ!")
                print(f"  â””â”€ ì„œë²„ ìˆ˜ì‹  í´ë¼ì´ì–¸íŠ¸: {received_clients}/{min_clients}")
                return True
            else:
                print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âŒ ê°€ì¤‘ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
                return False
        
        except Exception as e:
            print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âŒ ê°€ì¤‘ì¹˜ ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def fetch_aggregated_weights(self, round_num: int) -> bool:
        """
        ì„œë²„ì—ì„œ ì§‘ê³„ëœ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            round_num: ë¼ìš´ë“œ ë²ˆí˜¸
            
        Returns:
            ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ ì—¬ë¶€
        """
        print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] ì„œë²„ì—ì„œ ê°€ì¤‘ì¹˜ ìš”ì²­ ì¤‘...")
        try:
            # íƒ€ì„ì•„ì›ƒì„ 60ì´ˆë¡œ ì¦ê°€ (í° ê°€ì¤‘ì¹˜ ì „ì†¡ ì‹œê°„ ê³ ë ¤)
            response = requests.get(f'{self.server_url}/get_weights', timeout=60)
            
            if response.status_code == 200:
                data = response.json()
                server_round = data.get('round', 0)
                weight_format = data.get('format', 'json')
                
                # ë¼ìš´ë“œ í™•ì¸
                if server_round < round_num:
                    print(f"  âš ï¸  ì„œë²„ ê°€ì¤‘ì¹˜ê°€ ì•„ì§ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (ì„œë²„ ë¼ìš´ë“œ: {server_round}, ìš”ì²­ ë¼ìš´ë“œ: {round_num})")
                    return False
                
                # ê°€ì¤‘ì¹˜ ì—­ì§ë ¬í™” ë° ë¡œë“œ
                weights = self._deserialize_weights(data['weights'], format=weight_format)
                self.model.load_state_dict(weights)
                
                print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âœ… ì§‘ê³„ëœ ê°€ì¤‘ì¹˜ ìˆ˜ì‹  ì™„ë£Œ!")
                print(f"  â”œâ”€ ì„œë²„ ë¼ìš´ë“œ: {server_round}")
                print(f"  â””â”€ ì „ì†¡ í˜•ì‹: {weight_format}")
                return True
            else:
                print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âŒ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {response.status_code}")
                return False
        
        except requests.exceptions.Timeout:
            print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âŒ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸° íƒ€ì„ì•„ì›ƒ (60ì´ˆ ì´ˆê³¼)")
            print(f"  ğŸ’¡ ì„œë²„ê°€ ì‘ë‹µí•˜ëŠ” ë° ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return False
        except Exception as e:
            print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âŒ ê°€ì¤‘ì¹˜ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return False
    
    def _serialize_weights(self, weights: Dict) -> Dict:
        """
        ê°€ì¤‘ì¹˜ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
        í° ëª¨ë¸ì˜ ê²½ìš° ë§¤ìš° ëŠë¦¬ë¯€ë¡œ ë°”ì´ë„ˆë¦¬ ì••ì¶• ë°©ì‹ ê¶Œì¥
        """
        serialized = {}
        for key, value in weights.items():
            if isinstance(value, torch.Tensor):
                serialized[key] = {
                    'data': value.cpu().numpy().tolist(),
                    'shape': list(value.shape),
                    'dtype': str(value.dtype)
                }
            else:
                serialized[key] = value
        return serialized
    
    def _deserialize_weights(self, weights, format: str = 'json') -> Dict:
        """
        ê°€ì¤‘ì¹˜ ì—­ì§ë ¬í™”
        ë°”ì´ë„ˆë¦¬ ì••ì¶• í˜•ì‹ ë˜ëŠ” JSON í˜•ì‹ ëª¨ë‘ ì§€ì›
        """
        import base64
        import pickle
        import gzip
        
        # ë°”ì´ë„ˆë¦¬ ì••ì¶• í˜•ì‹ì¸ ê²½ìš°
        if format == 'binary_compressed' or (isinstance(weights, str) and len(weights) > 1000):
            try:
                # Base64 ë””ì½”ë”©
                decoded = base64.b64decode(weights.encode('utf-8'))
                # ì••ì¶• í•´ì œ
                decompressed = gzip.decompress(decoded)
                # Pickle ì—­ì§ë ¬í™”
                deserialized = pickle.loads(decompressed)
                # í…ì„œë¡œ ë³€í™˜ (ì´ë¯¸ í…ì„œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©)
                result = {}
                for k, v in deserialized.items():
                    if isinstance(v, torch.Tensor):
                        result[k] = v
                    elif isinstance(v, (list, tuple, np.ndarray)):
                        result[k] = torch.tensor(v)
                    else:
                        result[k] = v
                return result
            except Exception as e:
                print(f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âš ï¸  ë°”ì´ë„ˆë¦¬ ì—­ì§ë ¬í™” ì‹¤íŒ¨, JSON í˜•ì‹ìœ¼ë¡œ ì‹œë„: {e}")
        
        # JSON í˜•ì‹ (ê¸°ì¡´ ë°©ì‹)
        deserialized = {}
        for key, value in weights.items():
            if isinstance(value, dict) and 'data' in value:
                tensor = torch.tensor(value['data'], dtype=torch.float32)
                tensor = tensor.reshape(value['shape'])
                deserialized[key] = tensor
            else:
                deserialized[key] = value
        return deserialized
    
    def evaluate(self, test_loader: DataLoader) -> Dict:
        """
        ëª¨ë¸ í‰ê°€
        
        Args:
            test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
            
        Returns:
            í‰ê°€ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")
        
        print(f"\n[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] ëª¨ë¸ í‰ê°€ ì‹œì‘...")
        print(f"  â””â”€ í‰ê°€ ë°°ì¹˜ ìˆ˜: {len(test_loader)}")
        
        self.model.eval()
        total_loss = 0.0
        correct = 0
        total_samples = 0
        
        pbar = tqdm(
            test_loader,
            desc=f"[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] í‰ê°€ ì¤‘",
            unit="batch",
            ncols=100
        )
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(pbar):
                images = batch['image'].to(self.device)
                labels = batch['label'].to(self.device)
                
                outputs = self.model(images)
                loss = self.criterion(outputs, labels)
                
                batch_size = images.size(0)
                total_loss += loss.item() * batch_size
                total_samples += batch_size
                
                _, predicted = torch.max(outputs.data, 1)
                batch_correct = (predicted == labels).sum().item()
                correct += batch_correct
                
                # ì§„í–‰ ë°” ì—…ë°ì´íŠ¸
                current_acc = correct / total_samples if total_samples > 0 else 0.0
                current_loss = total_loss / total_samples if total_samples > 0 else 0.0
                pbar.set_postfix({
                    'Loss': f'{current_loss:.4f}',
                    'Acc': f'{current_acc:.4f}'
                })
        
        pbar.close()
        
        accuracy = correct / total_samples if total_samples > 0 else 0.0
        avg_loss = total_loss / total_samples if total_samples > 0 else 0.0
        
        print(f"\n[í´ë¼ì´ì–¸íŠ¸ {self.client_id}] âœ… í‰ê°€ ì™„ë£Œ!")
        print(f"  â”œâ”€ í‰ê·  ì†ì‹¤: {avg_loss:.6f}")
        print(f"  â”œâ”€ ì •í™•ë„: {accuracy:.4f} ({correct}/{total_samples})")
        print(f"  â””â”€ í‰ê°€ ìƒ˜í”Œ ìˆ˜: {total_samples}ê°œ\n")
        
        return {
            'loss': avg_loss,
            'accuracy': accuracy,
            'samples': total_samples
        }

