"""
ì—°í•©í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
Non-IID ë°ì´í„° ë¶„ë°°ë¥¼ í¬í•¨í•œ ì „ì²´ ì—°í•©í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
"""

import argparse
import time
import torch
from pathlib import Path
from threading import Thread

from models.aprilgan import AprilGAN
from models.cnn import create_cnn_model
from federated.server import FederatedServer
from federated.client import FederatedClient
from utils.client_data_loader import load_client_data
from utils.logger import create_logger
from pathlib import Path


def main():
    parser = argparse.ArgumentParser(
        description='ê¸ˆì† 3D í”„ë¦°íŒ… ê²°í•¨ ê²€ì¶œ ì—°í•©í•™ìŠµ ì‹¤í–‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰ (3ê°œ í´ë¼ì´ì–¸íŠ¸, 3 ë¼ìš´ë“œ)
  python train_federated.py --data-dir data

  # Non-IID ì •ë„ ì¡°ì ˆ (ë§¤ìš° í¸í–¥)
  python train_federated.py --data-dir data --non-iid-alpha 0.1

  # ë” ë§ì€ ë¼ìš´ë“œì™€ ì—í­
  python train_federated.py --data-dir data --num-rounds 10 --epochs 3
        """
    )
    
    # ë°ì´í„° ê´€ë ¨
    parser.add_argument(
        '--data-dir',
        type=Path,
        default=Path('data'),
        help='ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: data)'
    )
    
    # í´ë¼ì´ì–¸íŠ¸ ë° ì„œë²„ ì„¤ì •
    parser.add_argument(
        '--num-clients',
        type=int,
        default=3,
        help='í´ë¼ì´ì–¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: 3)'
    )
    parser.add_argument(
        '--min-clients',
        type=int,
        default=None,
        help='ìµœì†Œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: num-clients)'
    )
    parser.add_argument(
        '--server-port',
        type=int,
        default=5000,
        help='ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 5000)'
    )
    
    # Non-IID ì„¤ì •
    parser.add_argument(
        '--non-iid-alpha',
        type=float,
        default=0.5,
        help='Non-IID ì •ë„ (0.1: ë§¤ìš° í¸í–¥, 0.5: ë³´í†µ, 10.0: ê· ë“±) (ê¸°ë³¸ê°’: 0.5)'
    )
    
    # í•™ìŠµ ì„¤ì •
    parser.add_argument(
        '--num-rounds',
        type=int,
        default=3,
        help='ì—°í•©í•™ìŠµ ë¼ìš´ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 3)'
    )
    parser.add_argument(
        '--epochs',
        type=int,
        default=1,
        help='ê° ë¼ìš´ë“œë‹¹ ë¡œì»¬ í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸ê°’: 1)'
    )
    parser.add_argument(
        '--learning-rate',
        type=float,
        default=0.001,
        help='í•™ìŠµë¥  (ê¸°ë³¸ê°’: 0.001)'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=32,
        help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)'
    )
    
    # ë°ì´í„° ë¶„í• 
    parser.add_argument(
        '--train-ratio',
        type=float,
        default=0.8,
        help='í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.8)'
    )
    
    # ëª¨ë¸ ì„¤ì •
    parser.add_argument(
        '--backbone',
        type=str,
        default='resnet18',
        choices=['resnet18', 'resnet34', 'resnet50'],
        help='CNN ë°±ë³¸ ëª¨ë¸ (ê¸°ë³¸ê°’: resnet18)'
    )
    
    # ê¸°íƒ€
    parser.add_argument(
        '--use-few-shot',
        action='store_true',
        help='í“¨ìƒ· í•™ìŠµ ëª¨ë“œ ì‚¬ìš©'
    )
    parser.add_argument(
        '--device',
        type=str,
        default=None,
        help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: ìë™ ê°ì§€)'
    )
    
    # ë¡œê¹… ì˜µì…˜
    parser.add_argument(
        '--log-dir',
        type=Path,
        default=Path('logs'),
        help='ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: logs)'
    )
    parser.add_argument(
        '--experiment-name',
        type=str,
        default=None,
        help='ì‹¤í—˜ ì´ë¦„ (ê¸°ë³¸ê°’: íƒ€ì„ìŠ¤íƒ¬í”„)'
    )
    parser.add_argument(
        '--no-log',
        action='store_true',
        help='ë¡œê·¸ ì €ì¥ ë¹„í™œì„±í™”'
    )
    
    args = parser.parse_args()
    
    # ìµœì†Œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ì„¤ì •
    if args.min_clients is None:
        args.min_clients = args.num_clients
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device is None:
        args.device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    print(f"\n{'='*70}")
    print(f"ì—°í•©í•™ìŠµ ì‹œì‘")
    print(f"{'='*70}")
    print(f"  â”œâ”€ ë°ì´í„° ë””ë ‰í† ë¦¬: {args.data_dir}")
    print(f"  â”œâ”€ í´ë¼ì´ì–¸íŠ¸ ìˆ˜: {args.num_clients}ê°œ")
    print(f"  â”œâ”€ ìµœì†Œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜: {args.min_clients}ê°œ")
    print(f"  â”œâ”€ Non-IID ì •ë„ (alpha): {args.non_iid_alpha}")
    print(f"  â”œâ”€ ì—°í•©í•™ìŠµ ë¼ìš´ë“œ: {args.num_rounds}ê°œ")
    print(f"  â”œâ”€ ë¡œì»¬ í•™ìŠµ ì—í­: {args.epochs}ê°œ")
    print(f"  â”œâ”€ í•™ìŠµë¥ : {args.learning_rate}")
    print(f"  â”œâ”€ ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"  â”œâ”€ ë°±ë³¸ ëª¨ë¸: {args.backbone}")
    print(f"  â”œâ”€ ë””ë°”ì´ìŠ¤: {args.device}")
    print(f"  â”œâ”€ í“¨ìƒ· í•™ìŠµ: {'ì‚¬ìš©' if args.use_few_shot else 'ë¯¸ì‚¬ìš©'}")
    print(f"  â””â”€ ë¡œê·¸ ì €ì¥: {'ë¹„í™œì„±í™”' if args.no_log else f'{args.log_dir}'}")
    print(f"{'='*70}\n")
    
    # ë¡œê±° ì´ˆê¸°í™”
    logger = None
    if not args.no_log:
        logger = create_logger(
            log_dir=args.log_dir,
            experiment_name=args.experiment_name
        )
        
        # ì‹¤í—˜ ì„¤ì • ê¸°ë¡
        config = {
            'data_dir': str(args.data_dir),
            'num_clients': args.num_clients,
            'min_clients': args.min_clients,
            'non_iid_alpha': args.non_iid_alpha,
            'num_rounds': args.num_rounds,
            'epochs': args.epochs,
            'learning_rate': args.learning_rate,
            'batch_size': args.batch_size,
            'train_ratio': args.train_ratio,
            'backbone': args.backbone,
            'device': args.device,
            'use_few_shot': args.use_few_shot,
            'server_port': args.server_port
        }
        logger.log_config(config)
    
    # 1. AprilGAN ëª¨ë¸ ì´ˆê¸°í™”
    print("[1ë‹¨ê³„] AprilGAN ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    aprilgan = AprilGAN()
    print("  â””â”€ ì™„ë£Œ!\n")
    
    # 2. ë°ì´í„° ë¡œë“œ
    print("[2ë‹¨ê³„] Non-IID ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        train_loaders, val_loaders, defect_type_to_idx = load_client_data(
            data_dir=args.data_dir,
            aprilgan_model=aprilgan,
            num_clients=args.num_clients,
            train_ratio=args.train_ratio,
            batch_size=args.batch_size,
            patch_size=(224, 224),
            non_iid_alpha=args.non_iid_alpha,
            verbose=True
        )
        num_classes = len(defect_type_to_idx)
        
        # í´ë¼ì´ì–¸íŠ¸ë³„ ë¶„í¬ë¥¼ ë¡œê±°ì— ê¸°ë¡
        if logger is not None:
            from utils.bbox_utils import extract_bboxes_from_json, normalize_defect_type
            client_distributions = {}
            for client_id in range(args.num_clients):
                # í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ ê²°í•¨ ìœ í˜• í†µê³„ ìˆ˜ì§‘
                defect_counts = {}
                train_dataset = train_loaders[client_id].dataset
                val_dataset = val_loaders[client_id].dataset
                
                # JSON íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ (ë°ì´í„°ì…‹ì´ ê²½ë¡œë¥¼ ì €ì¥í•˜ëŠ” ê²½ìš°)
                total_samples = len(train_dataset) + len(val_dataset)
                
                # ìƒ˜í”Œì—ì„œ ê²°í•¨ ìœ í˜• í†µê³„ ìˆ˜ì§‘
                for idx in range(min(100, len(train_dataset))):  # ìƒ˜í”Œë§
                    try:
                        sample = train_dataset[idx]
                        if 'defect_type' in sample:
                            dtype = normalize_defect_type(sample['defect_type'])
                            defect_counts[dtype] = defect_counts.get(dtype, 0) + 1
                    except:
                        pass
                
                client_distributions[client_id] = {
                    'total_samples': total_samples,
                    'train_samples': len(train_dataset),
                    'val_samples': len(val_dataset),
                    'defect_distribution': defect_counts
                }
            
            logger.log_client_distribution(client_distributions)
    except Exception as e:
        print(f"  âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("  ğŸ’¡ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ê±°ë‚˜ --data-dir ì˜µì…˜ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # 3. CNN ëª¨ë¸ ìƒì„±
    print(f"\n[3ë‹¨ê³„] CNN ëª¨ë¸ ìƒì„± ì¤‘...")
    cnn_model = create_cnn_model(
        num_classes=num_classes,
        backbone=args.backbone,
        pretrained=True
    )
    print(f"  â””â”€ ì™„ë£Œ! (í´ë˜ìŠ¤ ìˆ˜: {num_classes})\n")
    
    # 4. ì„œë²„ ì‹œì‘
    print(f"[4ë‹¨ê³„] ì—°í•©í•™ìŠµ ì„œë²„ ì‹œì‘ ì¤‘...")
    server = FederatedServer(
        port=args.server_port,
        num_clients=args.num_clients,
        min_clients=args.min_clients
    )
    
    # ì´ˆê¸° ê°€ì¤‘ì¹˜ ì„¤ì •
    initial_weights = cnn_model.state_dict()
    server.set_initial_weights(initial_weights)
    
    # ì„œë²„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    server_thread = Thread(target=server.start, daemon=True)
    server_thread.start()
    
    # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
    time.sleep(2)
    print(f"  â””â”€ ì„œë²„ ì‹œì‘ ì™„ë£Œ! (í¬íŠ¸: {args.server_port})\n")
    
    # 5. í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    print(f"[5ë‹¨ê³„] í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...")
    clients = []
    server_url = f'http://localhost:{args.server_port}'
    
    for client_id in range(args.num_clients):
        client = FederatedClient(
            client_id=client_id,
            server_url=server_url,
            model=cnn_model,
            device=args.device
        )
        clients.append(client)
        print(f"  â”œâ”€ í´ë¼ì´ì–¸íŠ¸ {client_id} ìƒì„± ì™„ë£Œ")
    print(f"  â””â”€ ì´ {len(clients)}ê°œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ\n")
    
    # 6. ì—°í•©í•™ìŠµ ë¼ìš´ë“œ ì‹¤í–‰
    print(f"[6ë‹¨ê³„] ì—°í•©í•™ìŠµ ë¼ìš´ë“œ ì‹¤í–‰")
    print(f"{'='*70}\n")
    
    for round_num in range(args.num_rounds):
        print(f"\n{'='*70}")
        print(f"ë¼ìš´ë“œ {round_num + 1}/{args.num_rounds}")
        print(f"{'='*70}")
        
        # 6-1. í´ë¼ì´ì–¸íŠ¸ê°€ ì„œë²„ì—ì„œ ê°€ì¤‘ì¹˜ ìˆ˜ì‹ 
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 1ë‹¨ê³„: ê°€ì¤‘ì¹˜ ìˆ˜ì‹ ")
        for client in clients:
            client.fetch_aggregated_weights(round_num)
        
        # 6-2. ê° í´ë¼ì´ì–¸íŠ¸ê°€ ë¡œì»¬ ë°ì´í„°ë¡œ í•™ìŠµ
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 2ë‹¨ê³„: ë¡œì»¬ í•™ìŠµ")
        client_stats_list = []
        
        for client in clients:
            client_train_loader = train_loaders[client.client_id]
            
            if args.use_few_shot:
                # í“¨ìƒ· í•™ìŠµ ëª¨ë“œ (ì¶”í›„ êµ¬í˜„ í•„ìš”)
                print(f"  í´ë¼ì´ì–¸íŠ¸ {client.client_id}: í“¨ìƒ· í•™ìŠµ ëª¨ë“œ (ë¯¸êµ¬í˜„)")
                stats = client.train_local(
                    client_train_loader,
                    epochs=args.epochs,
                    learning_rate=args.learning_rate
                )
            else:
                # ì¼ë°˜ í•™ìŠµ ëª¨ë“œ
                stats = client.train_local(
                    client_train_loader,
                    epochs=args.epochs,
                    learning_rate=args.learning_rate
                )
            
            # í´ë¼ì´ì–¸íŠ¸ í†µê³„ ì €ì¥
            client_stat = {
                'client_id': client.client_id,
                'loss': stats.get('loss', 0.0),
                'accuracy': stats.get('accuracy', 0.0),
                'samples': stats.get('samples', 0),
                'data_size': len(train_loaders[client.client_id].dataset)
            }
            client_stats_list.append(client_stat)
        
        # 6-3. ê° í´ë¼ì´ì–¸íŠ¸ê°€ ê°€ì¤‘ì¹˜ë¥¼ ì„œë²„ë¡œ ì „ì†¡
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 3ë‹¨ê³„: ê°€ì¤‘ì¹˜ ì—…ë¡œë“œ")
        for client in clients:
            data_size = len(train_loaders[client.client_id].dataset)
            client.upload_weights(round_num, data_size)
        
        # 6-4. ì„œë²„ê°€ ê°€ì¤‘ì¹˜ ì§‘ê³„ (ìë™ìœ¼ë¡œ ìˆ˜í–‰ë¨)
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 4ë‹¨ê³„: ê°€ì¤‘ì¹˜ ì§‘ê³„")
        time.sleep(1)  # ì„œë²„ ì²˜ë¦¬ ëŒ€ê¸°
        
        aggregated_weights = server.get_aggregated_weights()
        server_stats = None
        if aggregated_weights is not None:
            print(f"  âœ… ê°€ì¤‘ì¹˜ ì§‘ê³„ ì™„ë£Œ (ë¼ìš´ë“œ {server.current_round})")
            server_stats = {
                'round': server.current_round,
                'aggregated': True,
                'num_clients': len(client_stats_list)
            }
        else:
            print(f"  âš ï¸  ì•„ì§ ì§‘ê³„ë˜ì§€ ì•ŠìŒ")
            server_stats = {
                'round': round_num,
                'aggregated': False,
                'num_clients': len(client_stats_list)
            }
        
        # ë¼ìš´ë“œ ë¡œê·¸ ê¸°ë¡
        if logger is not None:
            logger.log_round(round_num + 1, client_stats_list, server_stats)
        
        print(f"\në¼ìš´ë“œ {round_num + 1} ì™„ë£Œ!")
        print(f"{'='*70}\n")
    
    # 7. ìµœì¢… í‰ê°€
    print(f"\n{'='*70}")
    print(f"[7ë‹¨ê³„] ìµœì¢… ëª¨ë¸ í‰ê°€")
    print(f"{'='*70}\n")
    
    # ìµœì¢… ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸
    final_weights = server.get_aggregated_weights()
    if final_weights is not None:
        cnn_model.load_state_dict(final_weights)
        print("âœ… ìµœì¢… ì§‘ê³„ëœ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ\n")
        
        # ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ì˜ ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€
        cnn_model.eval()
        total_correct = 0
        total_samples = 0
        
        for client_id, val_loader in enumerate(val_loaders):
            client_correct = 0
            client_samples = 0
            
            with torch.no_grad():
                for batch in val_loader:
                    images = batch['image'].to(args.device)
                    labels = batch['label'].to(args.device)
                    
                    outputs = cnn_model(images)
                    _, predicted = torch.max(outputs, 1)
                    
                    batch_size = labels.size(0)
                    client_samples += batch_size
                    client_correct += (predicted == labels).sum().item()
            
            client_accuracy = client_correct / client_samples if client_samples > 0 else 0.0
            print(f"  í´ë¼ì´ì–¸íŠ¸ {client_id}: {client_accuracy:.4f} ({client_correct}/{client_samples})")
            
            total_samples += client_samples
            total_correct += client_correct
        
        overall_accuracy = total_correct / total_samples if total_samples > 0 else 0.0
        print(f"\n  ì „ì²´ ëª¨ë¸ ì •í™•ë„: {overall_accuracy:.4f} ({total_correct}/{total_samples})")
        
        # ìµœì¢… ê²°ê³¼ë¥¼ ë¡œê±°ì— ê¸°ë¡
        if logger is not None:
            final_results = {
                'overall_accuracy': overall_accuracy,
                'total_correct': total_correct,
                'total_samples': total_samples,
                'client_results': {}
            }
            
            # í´ë¼ì´ì–¸íŠ¸ë³„ ê²°ê³¼ ì¶”ê°€
            for client_id, val_loader in enumerate(val_loaders):
                client_correct = 0
                client_samples = 0
                
                with torch.no_grad():
                    for batch in val_loader:
                        images = batch['image'].to(args.device)
                        labels = batch['label'].to(args.device)
                        
                        outputs = cnn_model(images)
                        _, predicted = torch.max(outputs, 1)
                        
                        batch_size = labels.size(0)
                        client_samples += batch_size
                        client_correct += (predicted == labels).sum().item()
                
                client_accuracy = client_correct / client_samples if client_samples > 0 else 0.0
                final_results['client_results'][client_id] = {
                    'accuracy': client_accuracy,
                    'correct': client_correct,
                    'total': client_samples
                }
            
            logger.log_final_results(final_results)
            logger.save()
    else:
        print("  âš ï¸  ìµœì¢… ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        if logger is not None:
            logger.log_final_results({'error': 'ìµœì¢… ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ'})
            logger.save()
    
    print(f"\n{'='*70}")
    print(f"ì—°í•©í•™ìŠµ ì™„ë£Œ!")
    if logger is not None:
        print(f"ë¡œê·¸ ì €ì¥ ìœ„ì¹˜: {logger.get_log_path()}")
    print(f"{'='*70}\n")
    
    # ì„œë²„ ì¢…ë£Œ
    print("ì„œë²„ ì¢…ë£Œ ì¤‘...")
    # ì„œë²„ëŠ” ë°ëª¬ ìŠ¤ë ˆë“œì´ë¯€ë¡œ ìë™ìœ¼ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤


if __name__ == '__main__':
    main()

