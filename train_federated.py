"""
ì—°í•©í•™ìŠµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
Non-IID ë°ì´í„° ë¶„ë°°ë¥¼ í¬í•¨í•œ ì „ì²´ ì—°í•©í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
"""

import argparse
import time
import torch
from pathlib import Path
from threading import Thread

from models.aprilgan import AprilGAN
from models.cnn import create_cnn_model
from federated.server import FederatedServer
from federated.client import FederatedClient
from utils.client_data_loader import load_client_data
from utils.logger import create_logger
from utils.checkpoint import create_checkpoint_manager
from utils.metrics import evaluate_model, print_per_class_metrics
from pathlib import Path
import numpy as np


def main():
    parser = argparse.ArgumentParser(
        description='ê¸ˆì† 3D í”„ë¦°íŒ… ê²°í•¨ ê²€ì¶œ ì—°í•©í•™ìŠµ ì‹¤í–‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰ (3ê°œ í´ë¼ì´ì–¸íŠ¸, 3 ë¼ìš´ë“œ)
  python train_federated.py --data-dir data

  # Non-IID ì •ë„ ì¡°ì ˆ (ë§¤ìš° í¸í–¥)
  python train_federated.py --data-dir data --non-iid-alpha 0.1

  # ë” ë§ì€ ë¼ìš´ë“œì™€ ì—í­
  python train_federated.py --data-dir data --num-rounds 10 --epochs 3
        """
    )
    
    # ë°ì´í„° ê´€ë ¨
    parser.add_argument(
        '--data-dir',
        type=Path,
        default=Path('data'),
        help='ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: data)'
    )
    
    # í´ë¼ì´ì–¸íŠ¸ ë° ì„œë²„ ì„¤ì •
    parser.add_argument(
        '--num-clients',
        type=int,
        default=5,
        help='í´ë¼ì´ì–¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: 5)'
    )
    parser.add_argument(
        '--min-clients',
        type=int,
        default=None,
        help='ìµœì†Œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: num-clients)'
    )
    parser.add_argument(
        '--server-port',
        type=int,
        default=5000,
        help='ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 5000)'
    )
    
    # Non-IID ì„¤ì •
    parser.add_argument(
        '--non-iid-alpha',
        type=float,
        default=0.5,
        help='Non-IID ì •ë„ (0.1: ë§¤ìš° í¸í–¥, 0.5: ë³´í†µ, 10.0: ê· ë“±) (ê¸°ë³¸ê°’: 0.5)'
    )
    
    # í•™ìŠµ ì„¤ì •
    parser.add_argument(
        '--num-rounds',
        type=int,
        default=3,
        help='ì—°í•©í•™ìŠµ ë¼ìš´ë“œ ìˆ˜ (ê¸°ë³¸ê°’: 3)'
    )
    parser.add_argument(
        '--epochs',
        type=int,
        default=1,
        help='ê° ë¼ìš´ë“œë‹¹ ë¡œì»¬ í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸ê°’: 1)'
    )
    parser.add_argument(
        '--learning-rate',
        type=float,
        default=0.001,
        help='í•™ìŠµë¥  (ê¸°ë³¸ê°’: 0.001)'
    )
    parser.add_argument(
        '--batch-size',
        type=int,
        default=32,
        help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)'
    )
    
    # ë°ì´í„° ë¶„í• 
    parser.add_argument(
        '--train-ratio',
        type=float,
        default=0.8,
        help='í•™ìŠµ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.8)'
    )
    
    # ëª¨ë¸ ì„¤ì •
    parser.add_argument(
        '--backbone',
        type=str,
        default='resnet18',
        choices=['resnet18', 'resnet34', 'resnet50'],
        help='CNN ë°±ë³¸ ëª¨ë¸ (ê¸°ë³¸ê°’: resnet18)'
    )
    
    # ê¸°íƒ€
    parser.add_argument(
        '--use-few-shot',
        action='store_true',
        help='í“¨ìƒ· í•™ìŠµ ëª¨ë“œ ì‚¬ìš©'
    )
    parser.add_argument(
        '--device',
        type=str,
        default=None,
        help='ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ (ê¸°ë³¸ê°’: ìë™ ê°ì§€)'
    )
    
    # ë¡œê¹… ì˜µì…˜
    parser.add_argument(
        '--log-dir',
        type=Path,
        default=Path('logs'),
        help='ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: logs)'
    )
    parser.add_argument(
        '--experiment-name',
        type=str,
        default=None,
        help='ì‹¤í—˜ ì´ë¦„ (ê¸°ë³¸ê°’: íƒ€ì„ìŠ¤íƒ¬í”„)'
    )
    parser.add_argument(
        '--no-log',
        action='store_true',
        help='ë¡œê·¸ ì €ì¥ ë¹„í™œì„±í™”'
    )
    
    # ì²´í¬í¬ì¸íŠ¸ ì˜µì…˜
    parser.add_argument(
        '--checkpoint-dir',
        type=Path,
        default=Path('checkpoints'),
        help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: checkpoints)'
    )
    parser.add_argument(
        '--save-checkpoints',
        action='store_true',
        default=True,
        help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ í™œì„±í™” (ê¸°ë³¸ê°’: True)'
    )
    parser.add_argument(
        '--no-save-checkpoints',
        action='store_false',
        dest='save_checkpoints',
        help='ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë¹„í™œì„±í™”'
    )
    parser.add_argument(
        '--resume-from',
        type=Path,
        default=None,
        help='ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ (í•™ìŠµ ì¬ê°œìš©)'
    )
    
    args = parser.parse_args()
    
    # ìµœì†Œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜ ì„¤ì •
    if args.min_clients is None:
        args.min_clients = args.num_clients
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device is None:
        args.device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    print(f"\n{'='*70}")
    print(f"ì—°í•©í•™ìŠµ ì‹œì‘")
    print(f"{'='*70}")
    print(f"  â”œâ”€ ë°ì´í„° ë””ë ‰í† ë¦¬: {args.data_dir}")
    print(f"  â”œâ”€ í´ë¼ì´ì–¸íŠ¸ ìˆ˜: {args.num_clients}ê°œ")
    print(f"  â”œâ”€ ìµœì†Œ í´ë¼ì´ì–¸íŠ¸ ìˆ˜: {args.min_clients}ê°œ")
    print(f"  â”œâ”€ Non-IID ì •ë„ (alpha): {args.non_iid_alpha}")
    print(f"  â”œâ”€ ì—°í•©í•™ìŠµ ë¼ìš´ë“œ: {args.num_rounds}ê°œ")
    print(f"  â”œâ”€ ë¡œì»¬ í•™ìŠµ ì—í­: {args.epochs}ê°œ")
    print(f"  â”œâ”€ í•™ìŠµë¥ : {args.learning_rate}")
    print(f"  â”œâ”€ ë°°ì¹˜ í¬ê¸°: {args.batch_size}")
    print(f"  â”œâ”€ ë°±ë³¸ ëª¨ë¸: {args.backbone}")
    print(f"  â”œâ”€ ë””ë°”ì´ìŠ¤: {args.device}")
    print(f"  â”œâ”€ í“¨ìƒ· í•™ìŠµ: {'ì‚¬ìš©' if args.use_few_shot else 'ë¯¸ì‚¬ìš©'}")
    print(f"  â”œâ”€ ë¡œê·¸ ì €ì¥: {'ë¹„í™œì„±í™”' if args.no_log else f'{args.log_dir}'}")
    print(f"  â””â”€ ì²´í¬í¬ì¸íŠ¸: {'ë¹„í™œì„±í™”' if not args.save_checkpoints else f'{args.checkpoint_dir}'}")
    print(f"{'='*70}\n")
    
    # ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬ ìƒì„± (ë¡œê±°ì™€ ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì €ì—ì„œ ê³µìœ )
    config = {
        'data_dir': str(args.data_dir),
        'num_clients': args.num_clients,
        'min_clients': args.min_clients,
        'non_iid_alpha': args.non_iid_alpha,
        'num_rounds': args.num_rounds,
        'epochs': args.epochs,
        'learning_rate': args.learning_rate,
        'batch_size': args.batch_size,
        'train_ratio': args.train_ratio,
        'backbone': args.backbone,
        'device': args.device,
        'use_few_shot': args.use_few_shot,
        'server_port': args.server_port
    }
    
    # ë¡œê±° ì´ˆê¸°í™”
    logger = None
    if not args.no_log:
        try:
            logger = create_logger(
                log_dir=args.log_dir,
                experiment_name=args.experiment_name
            )
            logger.log_config(config)
        except Exception as e:
            print(f"  âš ï¸  ë¡œê±° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("  ğŸ’¡ ë¡œê·¸ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            import traceback
            traceback.print_exc()
            logger = None
    
    # ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    checkpoint_manager = None
    if args.save_checkpoints:
        try:
            checkpoint_manager = create_checkpoint_manager(
                checkpoint_dir=args.checkpoint_dir,
                experiment_name=args.experiment_name,
                save_best=True,
                save_latest=True,
                save_rounds=True
            )
            print(f"[ì²´í¬í¬ì¸íŠ¸] ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"  âš ï¸  ì²´í¬í¬ì¸íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("  ğŸ’¡ ì²´í¬í¬ì¸íŠ¸ ì—†ì´ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            import traceback
            traceback.print_exc()
            checkpoint_manager = None
    
    # 1. AprilGAN ëª¨ë¸ ì´ˆê¸°í™”
    print("[1ë‹¨ê³„] AprilGAN ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    aprilgan = AprilGAN()
    print("  â””â”€ ì™„ë£Œ!\n")
    
    # 2. ë°ì´í„° ë¡œë“œ
    print("[2ë‹¨ê³„] Non-IID ë°ì´í„° ë¡œë“œ ì¤‘...")
    try:
        train_loaders, val_loaders, test_loader, defect_type_to_idx = load_client_data(
            data_dir=args.data_dir,
            aprilgan_model=aprilgan,
            num_clients=args.num_clients,
            train_ratio=args.train_ratio,
            batch_size=args.batch_size,
            patch_size=(224, 224),
            non_iid_alpha=args.non_iid_alpha,
            verbose=True
        )
        num_classes = len(defect_type_to_idx)
        
        # í´ë¼ì´ì–¸íŠ¸ë³„ ë¶„í¬ë¥¼ ë¡œê±°ì— ê¸°ë¡
        if logger is not None:
            try:
                from utils.bbox_utils import extract_bboxes_from_json, normalize_defect_type
                client_distributions = {}
                
                # load_client_dataì—ì„œ ë°˜í™˜ëœ client_dataë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ
                # ë°ì´í„°ì…‹ì—ì„œ ì§ì ‘ ìƒ˜í”Œ ìˆ˜ë§Œ ê¸°ë¡
                for client_id in range(args.num_clients):
                    train_dataset = train_loaders[client_id].dataset
                    val_dataset = val_loaders[client_id].dataset
                    
                    total_samples = len(train_dataset) + len(val_dataset)
                    train_samples = len(train_dataset)
                    val_samples = len(val_dataset)
                    
                    # ê²°í•¨ ìœ í˜• í†µê³„ëŠ” ê°„ë‹¨í•˜ê²Œ ìƒ˜í”Œ ìˆ˜ë§Œ ê¸°ë¡
                    # (ì •í™•í•œ ë¶„í¬ëŠ” ì´ë¯¸ analyze_client_distributionì—ì„œ ì¶œë ¥ë¨)
                    client_distributions[client_id] = {
                        'total_samples': total_samples,
                        'train_samples': train_samples,
                        'val_samples': val_samples,
                        'defect_distribution': {}  # ë‚˜ì¤‘ì— í•„ìš”ì‹œ ì¶”ê°€ ê°€ëŠ¥
                    }
                
                logger.log_client_distribution(client_distributions)
            except Exception as e:
                print(f"  âš ï¸  í´ë¼ì´ì–¸íŠ¸ ë¶„í¬ ë¡œê¹… ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
    except Exception as e:
        print(f"  âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("  ğŸ’¡ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ê±°ë‚˜ --data-dir ì˜µì…˜ì„ í™•ì¸í•˜ì„¸ìš”.")
        return
    
    # 3. CNN ëª¨ë¸ ìƒì„±
    print(f"\n[3ë‹¨ê³„] CNN ëª¨ë¸ ìƒì„± ì¤‘...")
    cnn_model = create_cnn_model(
        num_classes=num_classes,
        backbone=args.backbone,
        pretrained=True
    )
    print(f"  â””â”€ ì™„ë£Œ! (í´ë˜ìŠ¤ ìˆ˜: {num_classes})\n")
    
    # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ (ìˆëŠ” ê²½ìš°)
    start_round = 0
    if args.resume_from is not None and checkpoint_manager is not None:
        try:
            checkpoint = checkpoint_manager.load_checkpoint(
                args.resume_from,
                cnn_model,
                device=torch.device(args.device)
            )
            start_round = checkpoint.get('round', 0) + 1
            print(f"[ì²´í¬í¬ì¸íŠ¸] âœ… í•™ìŠµ ì¬ê°œ: ë¼ìš´ë“œ {start_round}ë¶€í„° ì‹œì‘")
        except Exception as e:
            print(f"  âš ï¸  ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("  ğŸ’¡ ì²˜ìŒë¶€í„° í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            start_round = 0
    
    # 4. ì„œë²„ ì‹œì‘
    print(f"[4ë‹¨ê³„] ì—°í•©í•™ìŠµ ì„œë²„ ì‹œì‘ ì¤‘...")
    server = FederatedServer(
        port=args.server_port,
        num_clients=args.num_clients,
        min_clients=args.min_clients
    )
    
    # ì´ˆê¸° ê°€ì¤‘ì¹˜ ì„¤ì •
    initial_weights = cnn_model.state_dict()
    server.set_initial_weights(initial_weights)
    
    # ì„œë²„ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
    server_thread = Thread(target=server.start, daemon=True)
    server_thread.start()
    
    # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
    time.sleep(2)
    print(f"  â””â”€ ì„œë²„ ì‹œì‘ ì™„ë£Œ! (í¬íŠ¸: {args.server_port})\n")
    
    # 5. í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    print(f"[5ë‹¨ê³„] í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...")
    clients = []
    server_url = f'http://localhost:{args.server_port}'
    
    for client_id in range(args.num_clients):
        client = FederatedClient(
            client_id=client_id,
            server_url=server_url,
            model=cnn_model,
            device=args.device
        )
        clients.append(client)
        print(f"  â”œâ”€ í´ë¼ì´ì–¸íŠ¸ {client_id} ìƒì„± ì™„ë£Œ")
    print(f"  â””â”€ ì´ {len(clients)}ê°œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ\n")
    
    # 6. ì—°í•©í•™ìŠµ ë¼ìš´ë“œ ì‹¤í–‰
    print(f"[6ë‹¨ê³„] ì—°í•©í•™ìŠµ ë¼ìš´ë“œ ì‹¤í–‰")
    print(f"{'='*70}\n")
    
    for round_num in range(start_round, args.num_rounds):
        print(f"\n{'='*70}")
        print(f"ë¼ìš´ë“œ {round_num + 1}/{args.num_rounds}")
        print(f"{'='*70}")
        
        # 6-1. í´ë¼ì´ì–¸íŠ¸ê°€ ì„œë²„ì—ì„œ ê°€ì¤‘ì¹˜ ìˆ˜ì‹ 
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 1ë‹¨ê³„: ê°€ì¤‘ì¹˜ ìˆ˜ì‹ ")
        for client in clients:
            client.fetch_aggregated_weights(round_num)
        
        # 6-2. ê° í´ë¼ì´ì–¸íŠ¸ê°€ ë¡œì»¬ ë°ì´í„°ë¡œ í•™ìŠµ
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 2ë‹¨ê³„: ë¡œì»¬ í•™ìŠµ")
        client_stats_list = []
        
        for client in clients:
            client_train_loader = train_loaders[client.client_id]
            
            if args.use_few_shot:
                # í“¨ìƒ· í•™ìŠµ ëª¨ë“œ (ì¶”í›„ êµ¬í˜„ í•„ìš”)
                print(f"  í´ë¼ì´ì–¸íŠ¸ {client.client_id}: í“¨ìƒ· í•™ìŠµ ëª¨ë“œ (ë¯¸êµ¬í˜„)")
                stats = client.train_local(
                    client_train_loader,
                    epochs=args.epochs,
                    learning_rate=args.learning_rate
                )
            else:
                # ì¼ë°˜ í•™ìŠµ ëª¨ë“œ
                stats = client.train_local(
                    client_train_loader,
                    epochs=args.epochs,
                    learning_rate=args.learning_rate
                )
            
            # í´ë¼ì´ì–¸íŠ¸ í†µê³„ ì €ì¥
            client_stat = {
                'client_id': client.client_id,
                'loss': stats.get('loss', 0.0),
                'accuracy': stats.get('accuracy', 0.0),
                'samples': stats.get('samples', 0),
                'data_size': len(train_loaders[client.client_id].dataset)
            }
            client_stats_list.append(client_stat)
        
        # 6-3. ê° í´ë¼ì´ì–¸íŠ¸ê°€ ê°€ì¤‘ì¹˜ë¥¼ ì„œë²„ë¡œ ì „ì†¡
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 3ë‹¨ê³„: ê°€ì¤‘ì¹˜ ì—…ë¡œë“œ")
        for client in clients:
            data_size = len(train_loaders[client.client_id].dataset)
            client.upload_weights(round_num, data_size)
        
        # 6-4. ì„œë²„ê°€ ê°€ì¤‘ì¹˜ ì§‘ê³„ (ìë™ìœ¼ë¡œ ìˆ˜í–‰ë¨)
        print(f"\n[ë¼ìš´ë“œ {round_num + 1}] 4ë‹¨ê³„: ê°€ì¤‘ì¹˜ ì§‘ê³„")
        time.sleep(1)  # ì„œë²„ ì²˜ë¦¬ ëŒ€ê¸°
        
        aggregated_weights = server.get_aggregated_weights()
        server_stats = None
        if aggregated_weights is not None:
            print(f"  âœ… ê°€ì¤‘ì¹˜ ì§‘ê³„ ì™„ë£Œ (ë¼ìš´ë“œ {server.current_round})")
            server_stats = {
                'round': server.current_round,
                'aggregated': True,
                'num_clients': len(client_stats_list)
            }
        else:
            print(f"  âš ï¸  ì•„ì§ ì§‘ê³„ë˜ì§€ ì•ŠìŒ")
            server_stats = {
                'round': round_num,
                'aggregated': False,
                'num_clients': len(client_stats_list)
            }
        
        # ë¼ìš´ë“œ ë¡œê·¸ ê¸°ë¡
        if logger is not None:
            logger.log_round(round_num + 1, client_stats_list, server_stats)
        
        # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if checkpoint_manager is not None and aggregated_weights is not None:
            # ì§‘ê³„ëœ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸
            cnn_model.load_state_dict(aggregated_weights)
            
            # í‰ê·  ì„±ëŠ¥ ê³„ì‚°
            avg_accuracy = sum(c.get('accuracy', 0) for c in client_stats_list) / len(client_stats_list) if client_stats_list else 0.0
            avg_loss = sum(c.get('loss', 0) for c in client_stats_list) / len(client_stats_list) if client_stats_list else 0.0
            
            # ìµœê³  ì„±ëŠ¥ í™•ì¸
            is_best = checkpoint_manager.update_best(avg_accuracy, round_num + 1)
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            checkpoint_manager.save_checkpoint(
                model=cnn_model,
                round_num=round_num + 1,
                metrics={
                    'accuracy': avg_accuracy,
                    'loss': avg_loss,
                    'num_clients': len(client_stats_list)
                },
                config=config,
                is_best=is_best
            )
        
        print(f"\në¼ìš´ë“œ {round_num + 1} ì™„ë£Œ!")
        print(f"{'='*70}\n")
    
    # 7. ìµœì¢… í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì‚¬ìš©)
    print(f"\n{'='*70}")
    print(f"[7ë‹¨ê³„] ìµœì¢… ëª¨ë¸ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹)")
    print(f"{'='*70}\n")
    
    # ìµœì¢… ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸
    final_weights = server.get_aggregated_weights()
    if final_weights is not None:
        cnn_model.load_state_dict(final_weights)
        print("âœ… ìµœì¢… ì§‘ê³„ëœ ê°€ì¤‘ì¹˜ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ\n")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ í‰ê°€
        if test_loader is not None:
            # í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ìƒì„± (idx_to_defect_type)
            idx_to_defect_type = {idx: defect_type for defect_type, idx in defect_type_to_idx.items()}
            class_names = [idx_to_defect_type.get(i, f"Class_{i}") for i in range(num_classes)]
            
            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ í‰ê°€
            test_metrics = evaluate_model(
                model=cnn_model,
                data_loader=test_loader,
                device=torch.device(args.device),
                num_classes=num_classes,
                class_names=class_names
            )
            
            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ì¶œë ¥
            print_per_class_metrics(test_metrics, "ì„œë²„ ëª¨ë¸ ìµœì¢… ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹)")
            
            # ìµœì¢… ê²°ê³¼ë¥¼ ë¡œê±°ì— ê¸°ë¡
            if logger is not None:
                final_results = {
                    'test_metrics': test_metrics,
                    'class_names': class_names,
                    'test_samples': test_metrics['total_samples']
                }
                
                logger.log_final_results(final_results)
                logger.save()
        else:
            print("  âš ï¸  í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤. ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€í•©ë‹ˆë‹¤.")
            
            # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€ (í´ë°±)
            idx_to_defect_type = {idx: defect_type for defect_type, idx in defect_type_to_idx.items()}
            class_names = [idx_to_defect_type.get(i, f"Class_{i}") for i in range(num_classes)]
            
            # ëª¨ë“  ê²€ì¦ ë°ì´í„° í•©ì¹˜ê¸°
            from torch.utils.data import ConcatDataset, DataLoader
            all_val_datasets = [loader.dataset for loader in val_loaders]
            combined_val_dataset = ConcatDataset(all_val_datasets)
            combined_val_loader = DataLoader(
                combined_val_dataset,
                batch_size=args.batch_size,
                shuffle=False,
                num_workers=0
            )
            
            val_metrics = evaluate_model(
                model=cnn_model,
                data_loader=combined_val_loader,
                device=torch.device(args.device),
                num_classes=num_classes,
                class_names=class_names
            )
            
            print_per_class_metrics(val_metrics, "ì„œë²„ ëª¨ë¸ ìµœì¢… ì„±ëŠ¥ í‰ê°€ (ê²€ì¦ ë°ì´í„°ì…‹)")
            
            if logger is not None:
                final_results = {
                    'val_metrics': val_metrics,
                    'class_names': class_names,
                    'val_samples': val_metrics['total_samples']
                }
                
                logger.log_final_results(final_results)
                logger.save()
    else:
        print("  âš ï¸  ìµœì¢… ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        if logger is not None:
            logger.log_final_results({'error': 'ìµœì¢… ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŒ'})
            logger.save()
    
    print(f"\n{'='*70}")
    print(f"ì—°í•©í•™ìŠµ ì™„ë£Œ!")
    if logger is not None:
        print(f"ë¡œê·¸ ì €ì¥ ìœ„ì¹˜: {logger.get_log_path()}")
    if checkpoint_manager is not None:
        print(f"ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ìœ„ì¹˜: {checkpoint_manager.get_checkpoint_dir()}")
        print(f"  - ìµœê³  ì„±ëŠ¥: {checkpoint_manager.best_accuracy:.4f} (ë¼ìš´ë“œ {checkpoint_manager.best_round})")
    print(f"{'='*70}\n")
    
    # ì„œë²„ ì¢…ë£Œ
    print("ì„œë²„ ì¢…ë£Œ ì¤‘...")
    # ì„œë²„ëŠ” ë°ëª¬ ìŠ¤ë ˆë“œì´ë¯€ë¡œ ìë™ìœ¼ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤


if __name__ == '__main__':
    main()

