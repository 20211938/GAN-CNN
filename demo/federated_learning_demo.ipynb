{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# κΈμ† 3D ν”„λ¦°ν… κ²°ν•¨ κ²€μ¶ λ° λ¶„λ¥ - μ—°ν•©ν•™μµ λ°λ¨\n",
        "\n",
        "μ΄ λ…ΈνΈλ¶μ€ AprilGAN + CNN νμ΄ν”„λΌμΈμ„ μ—°ν•©ν•™μµ ν”„λ μ„μ›ν¬μ—μ„ μ‹μ—°ν•©λ‹λ‹¤.\n",
        "\n",
        "## νμ΄ν”„λΌμΈ κ°μ”\n",
        "\n",
        "1. **AprilGAN**: μ λ΅μƒ· μ΄μƒ νƒμ§€ (ν•™μµ λ¶ν•„μ”)\n",
        "2. **CNN**: κ²°ν•¨ μ ν• λ¶„λ¥ (μ—°ν•©ν•™μµ)\n",
        "3. **μ—°ν•©ν•™μµ**: μ—¬λ¬ ν΄λΌμ΄μ–ΈνΈκ°€ κ°€μ¤‘μΉλ§ κ³µμ ν•μ—¬ ν‘λ ¥ ν•™μµ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. ν™κ²½ μ„¤μ • λ° λ¨λ“ μ„ν¬νΈ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "# ν”„λ΅μ νΈ λ£¨νΈ κ²½λ΅ μ¶”κ°€\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# λ¨λ“ μ„ν¬νΈ\n",
        "from models.aprilgan import AprilGAN\n",
        "from models.cnn import DefectClassifierCNN, create_cnn_model\n",
        "from utils.data_loader import load_defect_data\n",
        "from utils.bbox_utils import extract_bboxes_from_json\n",
        "from federated.server import FederatedServer\n",
        "from federated.client import FederatedClient\n",
        "\n",
        "print(\"λ¨λ“ λ΅λ“ μ™„λ£\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. λ°μ΄ν„° μ¤€λΉ„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# λ°μ΄ν„° λ””λ ‰ν† λ¦¬ μ„¤μ •\n",
        "data_dir = Path(\"../data\")\n",
        "\n",
        "# λ°μ΄ν„° ν™•μΈ\n",
        "image_files = list(data_dir.glob(\"*.jpg\"))\n",
        "print(f\"μ΄ μ΄λ―Έμ§€ μ: {len(image_files)}\")\n",
        "\n",
        "if len(image_files) > 0:\n",
        "    print(f\"μ²« λ²μ§Έ μ΄λ―Έμ§€: {image_files[0]}\")\n",
        "    \n",
        "    # μƒν” μ΄λ―Έμ§€ ν™•μΈ\n",
        "    img = cv2.imread(str(image_files[0]))\n",
        "    if img is not None:\n",
        "        print(f\"μ΄λ―Έμ§€ ν¬κΈ°: {img.shape}\")\n",
        "        \n",
        "        # JSON νμΌ ν™•μΈ\n",
        "        json_file = image_files[0].with_suffix(\".jpg.json\")\n",
        "        if json_file.exists():\n",
        "            bboxes, defect_types = extract_bboxes_from_json(json_file)\n",
        "            print(f\"λ°”μ΄λ”©λ°•μ¤ μ: {len(bboxes)}\")\n",
        "            print(f\"κ²°ν•¨ μ ν•: {defect_types}\")\n",
        "            \n",
        "print(\"\\nπ’΅ Non-IID λ¶„λ°°: κ° ν΄λΌμ΄μ–ΈνΈκ°€ μ„λ΅ λ‹¤λ¥Έ κ²°ν•¨ μ ν• λ¶„ν¬λ¥Ό κ°€μ§€λ„λ΅ λ°μ΄ν„°κ°€ λ¶„λ°°λ©λ‹λ‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. AprilGAN λ¨λΈ μ΄κΈ°ν™” (μ λ΅μƒ·)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AprilGAN λ¨λΈ μ΄κΈ°ν™” (μ λ΅μƒ·, ν•™μµ λ¶ν•„μ”)\n",
        "aprilgan = AprilGAN()\n",
        "\n",
        "print(\"AprilGAN λ¨λΈ μ΄κΈ°ν™” μ™„λ£\")\n",
        "print(\"AprilGANμ€ μ λ΅μƒ· λ¨λΈλ΅ μ¶”κ°€ ν•™μµ μ—†μ΄ λ°”λ΅ μ‚¬μ© κ°€λ¥ν•©λ‹λ‹¤\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. AprilGAN μ΄μƒ νƒμ§€ μ‹μ—°\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# μƒν” μ΄λ―Έμ§€λ΅ AprilGAN ν…μ¤νΈ\n",
        "if len(image_files) > 0:\n",
        "    sample_image_path = image_files[0]\n",
        "    \n",
        "    # μ΄λ―Έμ§€ λ΅λ“\n",
        "    image_bgr = cv2.imread(str(sample_image_path))\n",
        "    image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # AprilGANμΌλ΅ μ΄μƒ νƒμ§€\n",
        "    result = aprilgan.detect(image_rgb)\n",
        "    \n",
        "    # κ²°κ³Ό μ‹κ°ν™”\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    # μ›λ³Έ μ΄λ―Έμ§€\n",
        "    axes[0].imshow(image_rgb)\n",
        "    axes[0].set_title(\"μ›λ³Έ μ΄λ―Έμ§€\")\n",
        "    axes[0].axis('off')\n",
        "    \n",
        "    # μ΄μƒ λ§μ¤ν¬\n",
        "    axes[1].imshow(result['anomaly_mask'], cmap='hot')\n",
        "    axes[1].set_title(f\"μ΄μƒ μμ—­ λ§μ¤ν¬ (μ μ: {result['anomaly_score']:.3f})\")\n",
        "    axes[1].axis('off')\n",
        "    \n",
        "    # μ›λ³Έ + μ΄μƒ μμ—­ μ¤λ²„λ μ΄\n",
        "    overlay = image_rgb.copy()\n",
        "    overlay[result['anomaly_mask'] == 1] = [255, 0, 0]  # λΉ¨κ°„μƒ‰μΌλ΅ ν‘μ‹\n",
        "    blended = cv2.addWeighted(image_rgb, 0.7, overlay, 0.3, 0)\n",
        "    axes[2].imshow(blended)\n",
        "    axes[2].set_title(f\"κ²€μ¶λ μ΄μƒ μμ—­ ({len(result['anomaly_regions'])}κ°)\")\n",
        "    axes[2].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"κ²€μ¶λ μ΄μƒ μμ—­ μ: {len(result['anomaly_regions'])}\")\n",
        "    for i, region in enumerate(result['anomaly_regions']):\n",
        "        print(f\"  μμ—­ {i+1}: ({region['x1']}, {region['y1']}) - ({region['x2']}, {region['y2']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. CNN λ¨λΈ μ΄κΈ°ν™” λ° λ°μ΄ν„° λ΅λ”©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN λ¨λΈ μƒμ„± λ° Non-IID λ°μ΄ν„° λ΅λ”©\n",
        "from utils.client_data_loader import load_client_data\n",
        "\n",
        "num_clients = 3\n",
        "non_iid_alpha = 0.5  # Non-IID μ •λ„ (0.1: λ§¤μ° νΈν–¥, 1.0: λ³΄ν†µ, 10.0: κ· λ“±)\n",
        "\n",
        "try:\n",
        "    # ν΄λΌμ΄μ–ΈνΈλ³„ Non-IID λ°μ΄ν„° λ΅λ“\n",
        "    train_loaders, val_loaders, defect_type_to_idx = load_client_data(\n",
        "        data_dir=data_dir,\n",
        "        aprilgan_model=aprilgan,\n",
        "        num_clients=num_clients,\n",
        "        train_ratio=0.8,\n",
        "        batch_size=16,\n",
        "        patch_size=(224, 224),\n",
        "        non_iid_alpha=non_iid_alpha,\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    num_classes = len(defect_type_to_idx)\n",
        "    print(f\"\\nκ²°ν•¨ μ ν• μ: {num_classes}\")\n",
        "    print(f\"ν΄λΌμ΄μ–ΈνΈλ³„ λ°μ΄ν„° λ΅λ” μƒμ„± μ™„λ£: {len(train_loaders)}κ°\")\n",
        "    \n",
        "    # CNN λ¨λΈ μƒμ„±\n",
        "    cnn_model = create_cnn_model(\n",
        "        num_classes=num_classes,\n",
        "        backbone='resnet18',\n",
        "        pretrained=True\n",
        "    )\n",
        "    \n",
        "    print(f\"CNN λ¨λΈ μƒμ„± μ™„λ£ (ν΄λμ¤ μ: {num_classes})\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"λ°μ΄ν„° λ΅λ”© μ¤λ¥: {e}\")\n",
        "    print(\"λ°λ¨λ¥Ό μ„ν•΄ λ”λ―Έ λ°μ΄ν„° μ‚¬μ©\")\n",
        "    num_classes = 5  # κΈ°λ³Έκ°’\n",
        "    cnn_model = create_cnn_model(num_classes=num_classes)\n",
        "    train_loaders = [None] * num_clients\n",
        "    val_loaders = [None] * num_clients\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. μ—°ν•©ν•™μµ μ„λ²„ μ‹μ‘\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# μ—°ν•©ν•™μµ μ„λ²„ μƒμ„±\n",
        "server = FederatedServer(\n",
        "    port=5000,\n",
        "    num_clients=3,\n",
        "    min_clients=2\n",
        ")\n",
        "\n",
        "# μ΄κΈ° κ°€μ¤‘μΉ μ„¤μ •\n",
        "initial_weights = cnn_model.state_dict()\n",
        "server.set_initial_weights(initial_weights)\n",
        "\n",
        "print(\"μ—°ν•©ν•™μµ μ„λ²„ μ¤€λΉ„ μ™„λ£\")\n",
        "print(\"μ„λ²„λ” λ³„λ„ μ¤λ λ“μ—μ„ μ‹¤ν–‰λ©λ‹λ‹¤\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# μ„λ²„λ¥Ό λ°±κ·ΈλΌμ΄λ“μ—μ„ μ‹μ‘\n",
        "import threading\n",
        "import time\n",
        "\n",
        "server_thread = threading.Thread(\n",
        "    target=server.start,\n",
        "    kwargs={'host': 'localhost', 'debug': False},\n",
        "    daemon=True\n",
        ")\n",
        "server_thread.start()\n",
        "\n",
        "# μ„λ²„κ°€ μ‹μ‘λ  λ•κΉμ§€ λ€κΈ°\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"μ„λ²„ μ‹μ‘ μ™„λ£\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. μ—°ν•©ν•™μµ ν΄λΌμ΄μ–ΈνΈ μƒμ„± λ° ν•™μµ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# μ—¬λ¬ ν΄λΌμ΄μ–ΈνΈ μƒμ„± (μ‹λ®¬λ μ΄μ…)\n",
        "clients = []\n",
        "num_clients = 3\n",
        "\n",
        "for client_id in range(num_clients):\n",
        "    client = FederatedClient(\n",
        "        client_id=client_id,\n",
        "        server_url='http://localhost:5000',\n",
        "        model=create_cnn_model(num_classes=num_classes)\n",
        "    )\n",
        "    clients.append(client)\n",
        "    print(f\"ν΄λΌμ΄μ–ΈνΈ {client_id} μƒμ„± μ™„λ£\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. μ—°ν•©ν•™μµ λΌμ΄λ“ μ‹¤ν–‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# μ—°ν•©ν•™μµ λΌμ΄λ“ μ‹¤ν–‰\n",
        "num_rounds = 3\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"λΌμ΄λ“ {round_num + 1}/{num_rounds}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # 1. κ° ν΄λΌμ΄μ–ΈνΈκ°€ μ„λ²„μ—μ„ μµμ‹  κ°€μ¤‘μΉ κ°€μ Έμ¤κΈ°\n",
        "    print(\"\\n[1λ‹¨κ³„] ν΄λΌμ΄μ–ΈνΈκ°€ μ„λ²„μ—μ„ κ°€μ¤‘μΉ μμ‹ \")\n",
        "    for client in clients:\n",
        "        client.fetch_aggregated_weights(round_num)\n",
        "    \n",
        "    # 2. κ° ν΄λΌμ΄μ–ΈνΈκ°€ λ΅μ»¬ λ°μ΄ν„°λ΅ ν•™μµ (Non-IID λ°μ΄ν„° μ‚¬μ©)\n",
        "    print(\"\\n[2λ‹¨κ³„] ν΄λΌμ΄μ–ΈνΈ λ΅μ»¬ ν•™μµ (Non-IID λ°μ΄ν„°)\")\n",
        "    if 'train_loaders' in locals() and train_loaders[0] is not None:\n",
        "        # μ‹¤μ  Non-IID λ°μ΄ν„°κ°€ μλ” κ²½μ°\n",
        "        for client in clients:\n",
        "            client_train_loader = train_loaders[client.client_id]\n",
        "            stats = client.train_local(client_train_loader, epochs=1, learning_rate=0.001)\n",
        "            print(f\"  ν΄λΌμ΄μ–ΈνΈ {client.client_id}: Loss={stats['loss']:.4f}, \"\n",
        "                  f\"Accuracy={stats['accuracy']:.4f}, Samples={stats['samples']}\")\n",
        "    else:\n",
        "        # λ”λ―Έ ν•™μµ (μ‹¤μ  κµ¬ν„μ—μ„λ” μ‹¤μ  λ°μ΄ν„° μ‚¬μ©)\n",
        "        print(\"  λ”λ―Έ ν•™μµ λ¨λ“ (μ‹¤μ  λ°μ΄ν„° ν•„μ”)\")\n",
        "    \n",
        "    # 3. κ° ν΄λΌμ΄μ–ΈνΈκ°€ ν•™μµλ κ°€μ¤‘μΉλ¥Ό μ„λ²„λ΅ μ „μ†΅\n",
        "    print(\"\\n[3λ‹¨κ³„] ν΄λΌμ΄μ–ΈνΈκ°€ κ°€μ¤‘μΉλ¥Ό μ„λ²„λ΅ μ „μ†΅\")\n",
        "    for client in clients:\n",
        "        # μ‹¤μ  λ°μ΄ν„° ν¬κΈ° μ‚¬μ©\n",
        "        if 'train_loaders' in locals() and train_loaders[client.client_id] is not None:\n",
        "            data_size = len(train_loaders[client.client_id].dataset)\n",
        "        else:\n",
        "            data_size = 100  # λ”λ―Έ κ°’\n",
        "        client.upload_weights(round_num, data_size)\n",
        "    \n",
        "    # 4. μ„λ²„κ°€ κ°€μ¤‘μΉ μ§‘κ³„ (μλ™μΌλ΅ μν–‰λ¨)\n",
        "    print(\"\\n[4λ‹¨κ³„] μ„λ²„κ°€ κ°€μ¤‘μΉ μ§‘κ³„\")\n",
        "    time.sleep(1)  # μ„λ²„ μ²λ¦¬ λ€κΈ°\n",
        "    \n",
        "    aggregated_weights = server.get_aggregated_weights()\n",
        "    if aggregated_weights is not None:\n",
        "        print(f\"  κ°€μ¤‘μΉ μ§‘κ³„ μ™„λ£ (λΌμ΄λ“ {server.current_round})\")\n",
        "    else:\n",
        "        print(\"  μ•„μ§ μ§‘κ³„λμ§€ μ•μ (λ” λ§μ€ ν΄λΌμ΄μ–ΈνΈ ν•„μ”)\")\n",
        "    \n",
        "    print(f\"\\nλΌμ΄λ“ {round_num + 1} μ™„λ£\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. μµμΆ… λ¨λΈ ν‰κ°€\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# μµμΆ… κ°€μ¤‘μΉλ΅ λ¨λΈ μ—…λ°μ΄νΈ\n",
        "final_weights = server.get_aggregated_weights()\n",
        "if final_weights is not None:\n",
        "    cnn_model.load_state_dict(final_weights)\n",
        "    print(\"μµμΆ… μ§‘κ³„λ κ°€μ¤‘μΉλ΅ λ¨λΈ μ—…λ°μ΄νΈ μ™„λ£\")\n",
        "    \n",
        "    # ν‰κ°€ (μ‹¤μ  λ°μ΄ν„°κ°€ μλ” κ²½μ°)\n",
        "    if 'val_loaders' in locals() and val_loaders[0] is not None:\n",
        "        print(\"\\n[μµμΆ… ν‰κ°€] λ¨λ“  ν΄λΌμ΄μ–ΈνΈμ κ²€μ¦ λ°μ΄ν„°λ΅ ν‰κ°€\")\n",
        "        cnn_model.eval()\n",
        "        \n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "        \n",
        "        # λ¨λ“  ν΄λΌμ΄μ–ΈνΈμ κ²€μ¦ λ°μ΄ν„°λ΅ ν‰κ°€\n",
        "        for client_id, val_loader in enumerate(val_loaders):\n",
        "            client_correct = 0\n",
        "            client_samples = 0\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for batch in val_loader:\n",
        "                    images = batch['image']\n",
        "                    labels = batch['label']\n",
        "                    \n",
        "                    outputs = cnn_model(images)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    \n",
        "                    batch_size = labels.size(0)\n",
        "                    client_samples += batch_size\n",
        "                    client_correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            client_accuracy = client_correct / client_samples if client_samples > 0 else 0.0\n",
        "            print(f\"  ν΄λΌμ΄μ–ΈνΈ {client_id}: {client_accuracy:.4f} ({client_correct}/{client_samples})\")\n",
        "            \n",
        "            total_samples += client_samples\n",
        "            total_correct += client_correct\n",
        "        \n",
        "        overall_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
        "        print(f\"\\nμ „μ²΄ λ¨λΈ μ •ν™•λ„: {overall_accuracy:.4f} ({total_correct}/{total_samples})\")\n",
        "    else:\n",
        "        print(\"ν‰κ°€λ¥Ό μ„ν•΄ μ‹¤μ  λ°μ΄ν„°κ°€ ν•„μ”ν•©λ‹λ‹¤\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. μ „μ²΄ νμ΄ν”„λΌμΈ μ”μ•½\n",
        "\n",
        "### νμ΄ν”„λΌμΈ νλ¦„:\n",
        "\n",
        "```\n",
        "μ›λ³Έ μ΄λ―Έμ§€\n",
        "    β†“\n",
        "[AprilGAN] μ λ΅μƒ· μ΄μƒ νƒμ§€ (ν•™μµ λ¶ν•„μ”)\n",
        "    β†“\n",
        "μ΄μƒ μμ—­ λ§μ¤ν¬/μΆν‘\n",
        "    β†“\n",
        "[CNN] κ²°ν•¨ μ ν• λ¶„λ¥ (μ—°ν•©ν•™μµ)\n",
        "    β†“\n",
        "κ²°ν•¨ μ ν• (\"Super Elevation\", \"Crack\", etc.)\n",
        "```\n",
        "\n",
        "### μ—°ν•©ν•™μµ κµ¬μ΅°:\n",
        "\n",
        "1. **AprilGAN**: μ λ΅μƒ· λ¨λΈλ΅ λ¨λ“  ν΄λΌμ΄μ–ΈνΈμ—μ„ λ™μΌν•κ² μ‚¬μ©\n",
        "2. **CNN**: κ° ν΄λΌμ΄μ–ΈνΈκ°€ λ΅μ»¬ λ°μ΄ν„°λ΅ ν•™μµ\n",
        "3. **κ°€μ¤‘μΉ μ „μ†΅**: CNN κ°€μ¤‘μΉλ§ μ„λ²„λ΅ μ „μ†΅ (λ°μ΄ν„°λ” μ „μ†΅ μ• ν•¨)\n",
        "4. **μ„λ²„ μ§‘κ³„**: Federated AveragingμΌλ΅ κ°€μ¤‘μΉ ν‰κ· ν™”\n",
        "5. **κ°€μ¤‘μΉ λ°°ν¬**: ν‰κ· ν™”λ κ°€μ¤‘μΉλ¥Ό λ¨λ“  ν΄λΌμ΄μ–ΈνΈμ— λ°°ν¬\n",
        "\n",
        "### ν•µμ‹¬ μ›μΉ™:\n",
        "\n",
        "- β… **λ°μ΄ν„° ν”„λΌμ΄λ²„μ‹**: μ›λ³Έ λ°μ΄ν„°λ” μ λ€ κ³µμ ν•μ§€ μ•μ\n",
        "- β… **κ°€μ¤‘μΉλ§ μ „μ†΅**: ν•™μµλ λ¨λΈ κ°€μ¤‘μΉλ§ μ„λ²„λ΅ μ „μ†΅\n",
        "- β… **μ„λ²„ μ§‘κ³„**: Federated AveragingμΌλ΅ ν‘λ ¥ ν•™μµ\n",
        "- β… **μ λ΅μƒ· ν™μ©**: AprilGANμ€ μ¶”κ°€ ν•™μµ μ—†μ΄ λ°”λ΅ μ‚¬μ©\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
